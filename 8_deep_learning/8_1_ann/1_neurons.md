# ANN Notes - 1: The Neuron
The basic building block of artificial neural networks.

## Biological Neurons
- The whole purpose of deep learning is to build a mathematical network that can mimic the way a human brain learns.
- A neuron is a nerve cell. It is the fundamental building block of the nervous system.
- Parts of Neurons
	- Cell Body
	- Dendrites: branches that connect to the cell body. It is the receiver of a signal for the neuron.
	- Axon: a long protrusion from the cell body that branches into smaller protrusions. It acts as the transmitter for the neuron, sending signals generated by this neuron to dendrites of other neurons.
	- There is no physical connection between axon of one neuron and dendrites of another neuron. All signals are transmitted through neurotransmitters across a synaptic gap between axons/dendrites.
	- A synapse is a junction between two neurons. It is where signal exchange occurs between two neurons.

## Representing Neurons in Machines
- Aka the node
- Gets input values, processes it, and generates an output signal.
- Can have multiple inputs and outputs.
- Input signals can come from other neurons.
- Color codes for this course.
	- Yellow: Input layer
	- Green: Hidden layer neuron/node
	- Blue: Connection between two neurons. Analogous to a synapse.
	- Red: Output
- In this particular example, we're looking at a neuron that gets inputs from the external environment (external input). It is also possible for neurons to get inputs from other neurons.
- The external inputs are analogous to the sensors (eyes/nose/ears/tongue/haptics) in our bodies. 
- The inputs in a neural network are independent variables X_1, X_2, X_3, ..., X_m. Each set of independent variables corresponds to a single row in the dataset.
- **Input variables** need to be **standardized** or **normalized** before they're fed to the neural network.
	- **Standardization**: (X_i - Mean(X))/(Standard Deviation (X))
	- **Normalization**: (X_i/Range(X))
	- Both techniques ensure that all input variables occupy roughly the same range of values. This ensures that an outlier for one feature does not skew the results of the neural network.
- **Output Value** 
	- Can be continuous e.g. price of a house
	- Can be categorical
		- Binary (1/0 e.g. malignant or benign tumour)
		- Multiclass (one of a finite set of values e.g. R/B/Y/G/O)
	- Can also have multiple input values. 
- **Synapses/Weights**
	- Interconnections between neurons in different layers.
	- Each connection is assigned a set of **weights**.
	- The learning of the neural network persists in the form of the weights.
	- The weights are adjusted during training and are crucial in determining which values get passed along the neural network. 

## What Happens in a Neuron?
- The neuron will take the weighted sum of all inputs: z = W1X1 + W2X2 + W3X3 + ... + W_mX_m
- It then passes this sum to an **activation function**, which will produce an output value (0/1) based on the weighted sum
- So each node's mathematical operation is represented by f(sum(W_i * X_i)) where `i` is the index of the input from the previous layer/external env.
- Each node then passes the output of its activation function to nodes in the next layer.